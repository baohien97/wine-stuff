{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(file_name):\n",
    "    results = []\n",
    "    with open(file_name) as csvfile:\n",
    "        wine_reader = csv.reader(csvfile, dialect=\"excel\", delimiter=';')\n",
    "        for row in wine_reader:\n",
    "            results.append(row)\n",
    "    name_features = results[0]\n",
    "    #print(name_features)\n",
    "    parsed_results = []\n",
    "    for row in results[1:]:\n",
    "        new_row = []\n",
    "        for num in row:\n",
    "            new_row.append(float(num))\n",
    "        parsed_results.append(new_row)\n",
    "    parsed_results = np.array(parsed_results)\n",
    "    n_instances = parsed_results.shape[0]\n",
    "    n_features = parsed_results.shape[1] - 1\n",
    "    labels = parsed_results[:, n_features]\n",
    "    instances = parsed_results[:, : n_features]\n",
    "    return instances, labels\n",
    "white_instances, white_labels = preprocess('winequality-white.csv')\n",
    "red_instances, red_labels = preprocess('winequality-red.csv')\n",
    "white_two_classes = np.array([0 if num <6 else 1 for num in white_labels])\n",
    "red_two_classes = np.array([0 if num <6 else 1 for num in red_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def three_classes(wine_labels):\n",
    "    transformed = []\n",
    "    for score in wine_labels:\n",
    "        if score <= 4:\n",
    "            transformed.append(\"bad\")\n",
    "        elif score <= 6:\n",
    "            transformed.append(\"medium\")\n",
    "        else:\n",
    "            transformed.append(\"good\")\n",
    "    return np.array(transformed)\n",
    "def four_classes(wine_labels):\n",
    "    transformed = []\n",
    "    for score in wine_labels:\n",
    "        if score <= 4:\n",
    "            transformed.append(\"bad\")\n",
    "        elif score == 5:\n",
    "            transformed.append(\"medium low\")\n",
    "        elif score == 6:\n",
    "            transformed.append(\"medium high\")\n",
    "        else:\n",
    "            transformed.append(\"good\")\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_three_classes = three_classes(white_labels)\n",
    "red_three_classes = three_classes(red_labels)\n",
    "white_four_classes = four_classes(white_labels)\n",
    "red_four_classes = four_classes(red_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression classifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix # for reporting\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # to normalize data (NN is very sensitive to this!)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV #BONUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune(params, clf, instances, labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(instances, labels)\n",
    "    gs = GridSearchCV(clf, param_grid=params, cv=5)\n",
    "    gs.fit(x_train, y_train)\n",
    "    return gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT classifier: \n",
      "\n",
      "best for white (2 classes) {'criterion': 'entropy', 'max_features': 'log2'}\n",
      "best for white (3 classes) {'criterion': 'entropy', 'max_features': None}\n",
      "best for white (4 classes) {'criterion': 'entropy', 'max_features': 'sqrt'}\n",
      "\n",
      "\n",
      "best for red (2 classes) {'criterion': 'entropy', 'max_features': None}\n",
      "best for red (3 classes) {'criterion': 'gini', 'max_features': 'sqrt'}\n",
      "best for red (4 classes) {'criterion': 'gini', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "params = {'max_features': [None, 'auto', 'sqrt', 'log2'], 'criterion': ['gini', 'entropy']}\n",
    "print(\"DT classifier: \\n\")\n",
    "print(\"best for white (2 classes)\", tune(params, DecisionTreeClassifier(), white_instances, white_two_classes))\n",
    "print(\"best for white (3 classes)\", tune(params, DecisionTreeClassifier(), white_instances, white_three_classes))\n",
    "print(\"best for white (4 classes)\", tune(params, DecisionTreeClassifier(), white_instances, white_four_classes))\n",
    "print(\"\\n\")\n",
    "print(\"best for red (2 classes)\", tune(params, DecisionTreeClassifier(), red_instances, red_two_classes))\n",
    "print(\"best for red (3 classes)\", tune(params, DecisionTreeClassifier(), red_instances, red_three_classes))\n",
    "print(\"best for red (4 classes)\", tune(params, DecisionTreeClassifier(), red_instances, red_four_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {'max_features': [None, 'auto', 'sqrt', 'log2'], 'criterion': ['entropy', 'gini']}\n",
    "print(\"tune(rfc_params, RandomForestClassifier(), white_instances, white_two_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF classifier: \n",
      "\n",
      "best for white (2 classes) {'criterion': 'entropy', 'max_features': 'sqrt'}\n",
      "best for white (3 classes) {'criterion': 'gini', 'max_features': 'log2'}\n",
      "best for white (4 classes) {'criterion': 'entropy', 'max_features': 'log2'}\n",
      "\n",
      "\n",
      "best for red (2 classes) {'criterion': 'entropy', 'max_features': 'log2'}\n",
      "best for red (3 classes) {'criterion': 'gini', 'max_features': 'sqrt'}\n",
      "best for red (4 classes) {'criterion': 'gini', 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"RF classifier: \\n\")\n",
    "print(\"best for white (2 classes)\", tune(params, RandomForestClassifier(), white_instances, white_two_classes))\n",
    "print(\"best for white (3 classes)\", tune(params, RandomForestClassifier(), white_instances, white_three_classes))\n",
    "print(\"best for white (4 classes)\", tune(params, RandomForestClassifier(), white_instances, white_four_classes))\n",
    "print(\"\\n\")\n",
    "print(\"best for red (2 classes)\", tune(params, RandomForestClassifier(), red_instances, red_two_classes))\n",
    "print(\"best for red (3 classes)\", tune(params, RandomForestClassifier(), red_instances, red_three_classes))\n",
    "print(\"best for red (4 classes)\", tune(params, RandomForestClassifier(), red_instances, red_four_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_report(clf_name, clf, instances, labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(instances, labels)\n",
    "    clf = clf\n",
    "    preds = clf.fit(x_train, y_train).predict(x_test)\n",
    "    display(HTML('<h4>' + clf_name + \"'s accuracy: </h4>\"))\n",
    "    print(accuracy_score(y_test, preds))\n",
    "    display(HTML('<strong>Report</strong>:\\n'))\n",
    "    print(classification_report(y_test, preds), \"\\n\")\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>For White Wine: </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>DT for white wine (2 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763265306122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.69      0.67       426\n",
      "          1       0.83      0.80      0.82       799\n",
      "\n",
      "avg / total       0.77      0.76      0.76      1225\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>DT for white wine (3 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772244897959\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.24      0.22      0.23        50\n",
      "       good       0.62      0.60      0.61       278\n",
      "     medium       0.84      0.86      0.85       897\n",
      "\n",
      "avg / total       0.77      0.77      0.77      1225\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>DT for white wine (4 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639183673469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.32      0.22      0.26        41\n",
      "       good       0.62      0.67      0.64       275\n",
      "medium high       0.66      0.65      0.66       541\n",
      " medium low       0.65      0.64      0.65       368\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1225\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>For Red Wine: </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>DT for red wine (2 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.71      0.74       185\n",
      "          1       0.77      0.82      0.79       215\n",
      "\n",
      "avg / total       0.77      0.77      0.77       400\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>DT for red wine (3 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.12      0.09      0.10        23\n",
      "       good       0.61      0.59      0.60        58\n",
      "     medium       0.87      0.90      0.88       319\n",
      "\n",
      "avg / total       0.79      0.81      0.80       400\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>DT for red wine (4 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.14      0.19      0.16        16\n",
      "       good       0.55      0.53      0.54        57\n",
      "medium high       0.54      0.59      0.57       145\n",
      " medium low       0.72      0.65      0.68       182\n",
      "\n",
      "avg / total       0.60      0.59      0.60       400\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(HTML('<h3>For White Wine: </h3>'))\n",
    "dt_preds_white_two = produce_report('DT for white wine (2 classes)', DecisionTreeClassifier(max_features='log2', \n",
    "                                      criterion='entropy'), white_instances, white_two_classes)\n",
    "dt_preds_white_three = produce_report('DT for white wine (3 classes)', DecisionTreeClassifier(max_features=None, \n",
    "                                      criterion='entropy'), white_instances, white_three_classes)\n",
    "dt_preds_white_four = produce_report('DT for white wine (4 classes)', DecisionTreeClassifier(max_features='sqrt', \n",
    "                                      criterion='entropy'), white_instances, white_four_classes)\n",
    "display(HTML('<h3>For Red Wine: </h3>'))\n",
    "dt_preds_red_two = produce_report('DT for red wine (2 classes)', DecisionTreeClassifier(max_features=None, \n",
    "                                      criterion='entropy'), red_instances, red_two_classes)\n",
    "dt_preds_red_three = produce_report('DT for red wine (3 classes)', DecisionTreeClassifier(max_features='sqrt', \n",
    "                                      criterion='gini'), red_instances, red_three_classes)\n",
    "dt_preds_red_four = produce_report('DT for red wine (4 classes)', DecisionTreeClassifier(max_features=None, \n",
    "                                      criterion='gini'), red_instances, red_four_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>For White Wine: </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>RF for white wine (2 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806530612245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.70      0.71       410\n",
      "          1       0.85      0.86      0.86       815\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1225\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>RF for white wine (3 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834285714286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.50      0.12      0.20        41\n",
      "       good       0.68      0.64      0.66       255\n",
      "     medium       0.87      0.92      0.90       929\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1225\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>RF for white wine (4 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61306122449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.25      0.30      0.27        40\n",
      "       good       0.59      0.63      0.61       260\n",
      "medium high       0.65      0.63      0.64       555\n",
      " medium low       0.62      0.61      0.62       370\n",
      "\n",
      "avg / total       0.62      0.61      0.61      1225\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>For Red Wine: </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>RF for red wine (2 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.84       192\n",
      "          1       0.86      0.82      0.84       208\n",
      "\n",
      "avg / total       0.84      0.84      0.84       400\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>RF for red wine (3 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.00      0.00      0.00        10\n",
      "       good       0.70      0.55      0.62        56\n",
      "     medium       0.90      0.95      0.93       334\n",
      "\n",
      "avg / total       0.85      0.87      0.86       400\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>RF for red wine (4 classes)'s accuracy: </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Report</strong>:\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.20      0.08      0.11        13\n",
      "       good       0.71      0.52      0.60        56\n",
      "medium high       0.61      0.68      0.64       158\n",
      " medium low       0.72      0.73      0.73       173\n",
      "\n",
      "avg / total       0.66      0.66      0.66       400\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(HTML('<h3>For White Wine: </h3>'))\n",
    "rf_preds_white_two = produce_report('RF for white wine (2 classes)', RandomForestClassifier(max_features='sqrt', \n",
    "                                      criterion='entropy'), white_instances, white_two_classes)\n",
    "rf_preds_white_three = produce_report('RF for white wine (3 classes)', RandomForestClassifier(max_features='log2', \n",
    "                                      criterion='gini'), white_instances, white_three_classes)\n",
    "rf_preds_white_four = produce_report('RF for white wine (4 classes)', DecisionTreeClassifier(max_features='log2', \n",
    "                                      criterion='entropy'), white_instances, white_four_classes)\n",
    "display(HTML('<h3>For Red Wine: </h3>'))\n",
    "rf_preds_red_two = produce_report('RF for red wine (2 classes)', RandomForestClassifier(max_features='log2', \n",
    "                                      criterion='entropy'), red_instances, red_two_classes)\n",
    "rf_preds_red_three = produce_report('RF for red wine (3 classes)', RandomForestClassifier(max_features='sqrt', \n",
    "                                      criterion='gini'), red_instances, red_three_classes)\n",
    "rf_preds_red_four = produce_report('RF for red wine (4 classes)', RandomForestClassifier(max_features='log2', \n",
    "                                      criterion='gini'), red_instances, red_four_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
